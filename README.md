
	
	

<div align="center">
<img width=200px height=200px src="images/sisl_pursuit.gif" alt="Project logo">
</div>
<h1 align="center">MAC PER Project</h1>



<div align="center">
MAC-PER is a multi-agent framework based on DDQN and Prioritized Experience Replay (PER)

</div>



	
	
	
## ğŸ§About

MAC-PER introduces [PER](https://arxiv.org/abs/1511.05952) and PER with buffer sharing on multi agent settings. We test our solution on the [Pursuit Environment](https://www.pettingzoo.ml/sisl/pursuit) using the Petting-zoo API. We procide three different modes of implementation. 

## ğŸ’¡Features

The project provides implementation of:
1. Standart DDQN agents.
2. PER based agents.
3. PER with buffer shraing between the agents.

## â›ï¸Built with

-   Keras
-   TensorFlow 2
-   PettingZoo
-   Panda
-   Pickle

## ğŸGetting Started

These instructions will help you to setup your own copy of "MAC-PER" on your local machine for development and testing purposes.

### ğŸ“šPrerequisite

-   Python 3


### ğŸ§°Installation

1. Clone this repo

2. Install all the dependencies

3. Run command:    
    ```bash
    sudo python3 Main.py
    ```

## ğŸ§¬Resources

<!-- Add links to all the resources you followed or referred to -->

-   [MAC Control Framework](https://github.com/sarah-keren/MAC)
-   [pythonlessons/Reinforcement_Learning](https://github.com/pythonlessons/Reinforcement_Learning/tree/master/05_CartPole-reinforcement-learning_PER_D3QN)

## ğŸ‰Acknowledgement
The PER implementation is mainly relying on the Pythonlessons repository:
-   [pythonlessons/Reinforcement_Learning](https://github.com/pythonlessons/Reinforcement_Learning/tree/master/05_CartPole-reinforcement-learning_PER_D3QN)
